{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickup all excel sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/UKfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/PLfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/PLpolicy.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ROthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/SEfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/UKheating.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/UKpolicy.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/PLheating.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ITthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/UKthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ESfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/FRthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/SEheating.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/PLthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/SEpolicy.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ROfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/SEthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/FRfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ESthermostat.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ITfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/DEfridge.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/ITpolicy.csv', '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing/DEthermostat.csv']\n",
      "23\n",
      "/home/kalyan/gitRepos/sin-Enchant/utils/../../cheetah/plots directory: exists\n"
     ]
    }
   ],
   "source": [
    "SURVEY_LIST = ['config_echoes.yaml', 'config_briskee.yaml', 'config_cheetah.yaml', 'config_natc.yaml']\n",
    "SURVEY_CHOICE = 2\n",
    "\n",
    "#TODO: Memory leak in cheetah ??\n",
    "#TODO: Correct first graph figure plots that are squashed along x-axis \n",
    "\n",
    "with open(SURVEY_LIST[SURVEY_CHOICE], 'r') as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "data_files = []\n",
    "dirs = list(set([__dir if os.path.isdir(os.path.join(args['data_dir'], __dir)) else '' for __dir in os.listdir(args['data_dir'])]))\n",
    "for _dir in dirs:\n",
    "    for filename in os.listdir(os.path.join(args['data_dir'], _dir)):\n",
    "        if args['format'] == 'rda': # scan for .rdata/.rda\n",
    "            if filename.endswith(\".rda\") or filename.endswith(\".rdata\"): \n",
    "                data_files.append(os.path.join(args['data_dir'], _dir, filename))\n",
    "            else:\n",
    "                continue\n",
    "        elif args['format'] == 'xls': # scan for .xls/.xlsx\n",
    "            if filename.endswith(\".xls\") or filename.endswith(\".xlsx\"): \n",
    "                 data_files.append(os.path.join(args['data_dir'], _dir, filename))\n",
    "            else:\n",
    "                continue\n",
    "        elif args['format'] == 'csv': # scan for .csv\n",
    "            if filename.endswith(\".csv\"): \n",
    "                 data_files.append(os.path.join(args['data_dir'], _dir, filename))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            print('Unsupported file format selcted')\n",
    "\n",
    "print(data_files)\n",
    "print(len(data_files))\n",
    "\n",
    "out_dir = os.path.join(os.getcwd(), args['out_dir'])\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "else:\n",
    "    print(f\"{out_dir} directory: exists\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks and iterate over individual sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get_csv_df_list', 'get_spss_df_list', 'get_xls_df_list']\n",
      "csv: <function SurveyParser.get_csv_df_list at 0x7f145fc9f050>\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import inspect\n",
    "\n",
    "class SurveyParser(object):\n",
    "    \n",
    "    default_args = {\n",
    "        'separator': ',',\n",
    "        'ignore_files_with_phrases': ['codebook', 'codes_labels']\n",
    "    }\n",
    "    \n",
    "    def get_xls_df_list(self, \n",
    "                        _data_files, \n",
    "                        **kwargs):\n",
    "        survey_df_dict = {}\n",
    "        remove_files_with_phrases = kwargs.default_args['ignore_files_with_phrases'] if 'ignore_files_with_phrases' in kwargs.keys() else self.default_args['ignore_files_with_phrases']\n",
    "        data_files = [_file for _file in _data_files if not any(phrase in _file for phrase in remove_files_with_phrases)]\n",
    "\n",
    "        for _file in data_files:\n",
    "            try:\n",
    "                sheet = pd.read_excel(_file, sheet_name=0) # Access the first sheet the other are codes and questionaire interpretations\n",
    "            except Exception as e:\n",
    "                print('Exception caught in xls')\n",
    "\n",
    "                _csv = '.'.join(_file.split('.')[:-1])+'.csv'\n",
    "                if os.path.exists(_csv+'.0'):\n",
    "                    print('File exists: Skip xls to csv conversion')\n",
    "                else:\n",
    "                    #pdb.set_trace()\n",
    "                    # Try converting xls to csv through CLI\n",
    "                    cmd = ['ssconvert', '-S', _file, _csv]\n",
    "                    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "                    o, e = proc.communicate()\n",
    "\n",
    "                sheet = pd.read_csv(_csv+'.0')\n",
    "\n",
    "            name = _file.replace(\" \", \"_\").split('/')[-1]\n",
    "            survey_df_dict[name] = sheet\n",
    "            sheet = None\n",
    "\n",
    "        return survey_df_dict\n",
    "\n",
    "    def get_csv_df_list(self, \n",
    "                        _data_files, \n",
    "                        **kwargs):\n",
    "        survey_df_dict = {}\n",
    "        remove_files_with_phrases = kwargs['ignore_files_with_phrases'] if 'ignore_files_with_phrases' in kwargs.keys() else self.default_args['ignore_files_with_phrases']\n",
    "        separator = kwargs['separator'] if 'separator' in kwargs.keys() else self.default_args['separator']\n",
    "        data_files = [_file for _file in _data_files if not any(phrase in _file for phrase in remove_files_with_phrases)]\n",
    "        \n",
    "        for _file in data_files:\n",
    "            sheet = pd.read_csv(_file, \n",
    "                                sep=separator,\n",
    "                                encoding='unicode_escape',\n",
    "                               low_memory=False)\n",
    "\n",
    "            name = _file.replace(\" \", \"_\").split('/')[-1]\n",
    "            survey_df_dict[name] = sheet\n",
    "            sheet = None\n",
    "\n",
    "        return survey_df_dict\n",
    "\n",
    "    def get_spss_df_list(self, \n",
    "                        _data_files, \n",
    "                        **kwargs):\n",
    "        return survey_df_dict\n",
    "\n",
    "    \n",
    "def get_methods(class_arg):\n",
    "\n",
    "    assert inspect.isclass(class_arg), 'Expecting a class as an argument'\n",
    "    \n",
    "    method_list = []\n",
    "    # attribute is a string representing the attribute name\n",
    "    for attribute in dir(class_arg):\n",
    "        # Get the attribute value\n",
    "        attribute_value = getattr(class_arg, attribute)\n",
    "        # Check that it is callable\n",
    "        if callable(attribute_value):\n",
    "            # Filter all dunder (__ prefix) methods\n",
    "            if attribute.startswith('__') == False:\n",
    "                method_list.append(attribute)\n",
    "\n",
    "    return method_list\n",
    "\n",
    "\n",
    "def get_method_fn(method,\n",
    "                  method_key,\n",
    "                  methods_list,\n",
    "                  methods_class):\n",
    "    \n",
    "    assert method in methods_list, f'Error: Improper method selected in {method_key} in config.yaml'\n",
    "    fn_method = getattr(methods_class, method)\n",
    "    print(f\"{method_key}: {fn_method}\")\n",
    "    return fn_method\n",
    "\n",
    "\n",
    "parser_class_inst = SurveyParser()\n",
    "parser_list = get_methods(SurveyParser)\n",
    "print(parser_list)\n",
    "parser_fn = get_method_fn(f\"get_{args['format']}_df_list\",\n",
    "                          args['format'],\n",
    "                          parser_list,\n",
    "                          SurveyParser)\n",
    "\n",
    "survey_df_dict = parser_fn(parser_class_inst, data_files, **args)  # Example of procedure call with class instance passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKfridge.csv: (7856, 177)\n",
      "PLfridge.csv: (7888, 129)\n",
      "PLpolicy.csv: (18306, 112)\n",
      "ROthermostat.csv: (5616, 172)\n",
      "SEfridge.csv: (9584, 129)\n",
      "UKheating.csv: (8376, 162)\n",
      "UKpolicy.csv: (16686, 112)\n",
      "PLheating.csv: (11256, 155)\n",
      "ITthermostat.csv: (5148, 151)\n",
      "UKthermostat.csv: (7584, 176)\n",
      "ESfridge.csv: (7248, 121)\n",
      "FRthermostat.csv: (6000, 172)\n",
      "SEheating.csv: (9540, 155)\n",
      "PLthermostat.csv: (5688, 172)\n",
      "SEpolicy.csv: (18072, 112)\n",
      "ROfridge.csv: (9504, 129)\n",
      "SEthermostat.csv: (6900, 172)\n",
      "FRfridge.csv: (17184, 130)\n",
      "ESthermostat.csv: (8832, 167)\n",
      "ITfridge.csv: (6640, 120)\n",
      "DEfridge.csv: (7008, 138)\n",
      "ITpolicy.csv: (18234, 112)\n",
      "DEthermostat.csv: (6876, 178)\n"
     ]
    }
   ],
   "source": [
    "'''TODO: Handle None dfs'''\n",
    "for name, survey_df in survey_df_dict.items():\n",
    "    print(f\"{name}: {survey_df.shape}\")\n",
    "#print(survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurveyConditioning(object):\n",
    "    \n",
    "    def get_nan_idices(sheet):\n",
    "        '''\n",
    "        '''\n",
    "        idx = np.argwhere(pd.isnull(sheet).to_numpy()) #2D indices\n",
    "        #print(idx)\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "    def no_nan(_sheet):\n",
    "        '''\n",
    "        '''\n",
    "        sheet = _sheet.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "        #print(sheet.shape)\n",
    "        return sheet\n",
    "\n",
    "    def substitute_nan(_sheet):\n",
    "        '''\n",
    "        '''\n",
    "        sheet = _sheet.fillna(0.0)\n",
    "        #print(sheet.shape)\n",
    "        return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get_nan_idices', 'no_nan', 'substitute_nan']\n"
     ]
    }
   ],
   "source": [
    "conditioning_class_inst = SurveyConditioning()\n",
    "methods_list = get_methods(SurveyConditioning)\n",
    "print(methods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format': 'csv', 'separator': ',', 'data_dir': '/media/windowsC/SIN_Desktop/ENCHANT/wp3_datasets/cheetah_data_sharing', 'out_dir': '../../cheetah/plots', 'surveys': {'global': {'histogram': {'enable': True, 'ROWS': 10, 'COLS': 10, 'SIZE': ['8*8', '6*8'], 'padding': 1.0}, 'conditioning': 'substitute_nan'}, 'DEfridge': {'histogram': {'ROWS': 14}}, 'DEthermostat': {'histogram': {'ROWS': 18}}, 'ESfridge': {'histogram': {'ROWS': 13}}, 'ESthermostat': {'histogram': {'ROWS': 17}}, 'FRfridge': {'histogram': {'ROWS': 13}}, 'FRthermostat': {'histogram': {'ROWS': 18}}, 'ITfridge': {'histogram': {'ROWS': 12}}, 'ITpolicy': {'histogram': {'ROWS': 12}}, 'ITthermostat': {'histogram': {'ROWS': 16}}, 'PLfridge': {'histogram': {'ROWS': 13}}, 'PLheating': {'histogram': {'ROWS': 16}}, 'PLpolicy': {'histogram': {'ROWS': 12}}, 'PLthermostat': {'histogram': {'ROWS': 18}}, 'ROfridge': {'histogram': {'ROWS': 13}}, 'ROthermostat': {'histogram': {'ROWS': 18}}, 'SEfridge': {'histogram': {'ROWS': 13}}, 'SEheating': {'histogram': {'ROWS': 16}}, 'SEpolicy': {'histogram': {'ROWS': 12}}, 'SEthermostat': {'histogram': {'ROWS': 18}}, 'UKfridge': {'histogram': {'ROWS': 18}}, 'UKheating': {'histogram': {'ROWS': 17}}, 'UKpolicy': {'histogram': {'ROWS': 12}}, 'UKthermostat': {'histogram': {'ROWS': 18}}}}\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DEfridge', 'DEthermostat', 'ESfridge', 'ESthermostat', 'FRfridge', 'FRthermostat', 'ITfridge', 'ITpolicy', 'ITthermostat', 'PLfridge', 'PLheating', 'PLpolicy', 'PLthermostat', 'ROfridge', 'ROthermostat', 'SEfridge', 'SEheating', 'SEpolicy', 'SEthermostat', 'UKfridge', 'UKheating', 'UKpolicy', 'UKthermostat'])\n",
      "> <ipython-input-8-36f0456c58e9>(86)<module>()\n",
      "-> global_settings = deepcopy(survey_global_settings)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m============================================ DEfridge ============================================\u001b[0m\n",
      "survey_global_settings:{'histogram': {'enable': True, 'ROWS': 10, 'COLS': 10, 'SIZE': ['8*8', '6*8'], 'padding': 1.0}, 'conditioning': 'substitute_nan'}\n",
      ", val:{'histogram': {'enable': True, 'ROWS': 14, 'COLS': 10, 'SIZE': ['8*8', '6*8'], 'padding': 1.0}, 'conditioning': 'substitute_nan'}\n",
      "DEfridge: <function SurveyConditioning.substitute_nan at 0x7f145a867320>\n",
      "before:(7008, 138), after:(7008, 138)\n",
      "> <ipython-input-8-36f0456c58e9>(85)<module>()\n",
      "-> pdb.set_trace()\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PlottingClass:\n",
    "    def build_histogram(self,\n",
    "                        out_dir,\n",
    "                        parsed_df,\n",
    "                        settings,\n",
    "                        survey_name,\n",
    "                        ignore_label=0):\n",
    "        #df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'], 'population': [1864, 22000, 80000]}, index=['panda', 'polar', 'koala'])\n",
    "        parsed_df = parsed_df.iloc[settings.get(\"n_discard_columns\", 1):, :]\n",
    "        ignore_labels = settings.get(\"ignore_labels\", [ignore_label])\n",
    "\n",
    "        ROWS, COLS, SIZE = settings.get(\"ROWS\", 0), settings.get(\"COLS\", 0), settings.get(\"SIZE\", (['8*8', '6*8']))\n",
    "        assert not (ROWS == 0 and COLS == 0), f'{survey_name} Error: ROWS/COL value not specified in config.yaml'\n",
    "\n",
    "        SIZE = list(map(lambda x: eval(x), SIZE))\n",
    "        fig, axes = plt.subplots(figsize=SIZE, dpi=300, nrows=ROWS, ncols=COLS)\n",
    "        idx = 0\n",
    "        for name, col in parsed_df.items():\n",
    "            #assert all(col.map(type) == int) or all(col.map(type) == float)\n",
    "            sr_count = col.value_counts()\n",
    "            _ignore_labels = [label for label in ignore_labels if label in sr_count.keys()]\n",
    "            if len(_ignore_labels) > 0:\n",
    "                sr_count.drop(labels=_ignore_labels, inplace=True)\n",
    "                #pdb.set_trace()\n",
    "\n",
    "            if sr_count.sum() > 0 and False:  #Display opitions with responses\n",
    "                i, j = idx // COLS, idx % COLS\n",
    "                idx += 1\n",
    "                if i>= ROWS or j>= COLS:\n",
    "                    pdb.set_trace()\n",
    "\n",
    "                #print(sr_count.keys().dtype, sr_count.values.dtype)\n",
    "                ax = axes[i, j]\n",
    "                FIRST_TIME = True\n",
    "                while FIRST_TIME:\n",
    "                    try:\n",
    "                        ax.bar(sr_count.keys(), sr_count.values, align='center', color='#607c8e')\n",
    "                        ax.plot(sr_count.keys(), sr_count.values, marker=\"o\", linestyle=\"\", alpha=0.8, color=\"b\")\n",
    "                        FIRST_TIME = False\n",
    "                    except TypeError:\n",
    "                        if FIRST_TIME:\n",
    "                            sr_count.index = list(map(str, list(sr_count.keys())))  # Ensure consistent type first time per plot\n",
    "                            FIRST_TIME = False\n",
    "                        else:\n",
    "                            pdb.set_trace()\n",
    "                ax.set_title(f'{name}', fontsize=7, fontweight='bold', color='blue')\n",
    "\n",
    "                ax.xaxis.set_tick_params(labelsize=5, labelcolor='r')\n",
    "                ax.set_xlabel(f'response[{sr_count.sum()}]', fontsize=5, fontweight='bold')\n",
    "                ax.yaxis.set_tick_params(labelsize=5, labelcolor='r')\n",
    "                ax.set_ylabel('count', fontsize=5, fontweight='bold')\n",
    "                ax.grid(axis='y', alpha=0.75)\n",
    "\n",
    "        padding = settings.get(\"padding\", 3.0)\n",
    "        fig.tight_layout(pad=padding)\n",
    "        plt.savefig(os.path.join(out_dir,f'{survey_name}.png'), bbox_inches='tight')\n",
    "        \n",
    "        fig.clear()\n",
    "        plt.close(fig)\n",
    "        plt.close('all')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "\n",
    "try:\n",
    "    survey_global_settings = args['surveys'].pop('global')\n",
    "except \"KeyError\":\n",
    "    survey_global_settings = None\n",
    "\n",
    "def recursive_parse_settings(given_setting, modify_setting):\n",
    "    for key, val in modify_setting.items():\n",
    "        if isinstance(val, dict):\n",
    "            recursive_parse_settings(given_setting[key], val)\n",
    "        else:\n",
    "            given_setting[key] = val\n",
    "    return given_setting\n",
    "\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "print(args['surveys'].keys())\n",
    "for key, _val in args['surveys'].items():\n",
    "    pdb.set_trace()\n",
    "    global_settings = deepcopy(survey_global_settings)\n",
    "    print(colored(f'============================================ {key} ============================================', 'yellow'))\n",
    "    val = recursive_parse_settings(global_settings, _val) if survey_global_settings is not None else _val\n",
    "    print(f\"survey_global_settings:{survey_global_settings}\\n, val:{val}\")\n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    method_fn = get_method_fn(val['conditioning'],\n",
    "                              key,\n",
    "                              methods_list,\n",
    "                              SurveyConditioning)\n",
    "    \n",
    "    matching_df = [survey_df for file_name, survey_df in survey_df_dict.items() if key in file_name]\n",
    "    assert len(matching_df) > 0, 'Error: Improper survey name in config.yaml'\n",
    "    parsed_df = method_fn(matching_df[0])  # Example of procedure call without class instance passing\n",
    "    print(f\"before:{matching_df[0].shape}, after:{parsed_df.shape}\")\n",
    "    \n",
    "    pltClass = PlottingClass()\n",
    "    # Build a histogram of each column in df\n",
    "    if val['histogram']['enable']:\n",
    "        pltClass.build_histogram(out_dir, \n",
    "                        parsed_df,\n",
    "                        val['histogram'], \n",
    "                        f\"{key}_{val['conditioning']}\")\n",
    "    del pltClass, global_settings, val, method_fn, matching_df, parsed_df\n",
    "    gc.collect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
